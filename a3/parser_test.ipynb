{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
    }
   ],
   "source": [
    "from parser_transitions import *\n",
    "from parser_model import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_dependencies(name, deps, ex_deps):\n",
    "    \"\"\"Tests the provided dependencies match the expected dependencies\"\"\"\n",
    "    deps = tuple(sorted(deps))\n",
    "    assert deps == ex_deps, \\\n",
    "        \"{:} test resulted in dependency list {:}, expected {:}\".format(name, deps, ex_deps)\n",
    "\n",
    "\n",
    "def test_minibatch_parse():\n",
    "    \"\"\"Simple tests for the minibatch_parse function\n",
    "    Warning: these are not exhaustive\n",
    "    \"\"\"\n",
    "\n",
    "    # Unidirectional arcs test\n",
    "    sentences = [[\"right\", \"arcs\", \"only\"],\n",
    "                 [\"right\", \"arcs\", \"only\", \"again\"],\n",
    "                 [\"left\", \"arcs\", \"only\"],\n",
    "                 [\"left\", \"arcs\", \"only\", \"again\"]]\n",
    "    deps = minibatch_parse(sentences, DummyModel(), 2)\n",
    "    test_dependencies(\"minibatch_parse\", deps[0],\n",
    "                      (('ROOT', 'right'), ('arcs', 'only'), ('right', 'arcs')))\n",
    "    test_dependencies(\"minibatch_parse\", deps[1],\n",
    "                      (('ROOT', 'right'), ('arcs', 'only'), ('only', 'again'), ('right', 'arcs')))\n",
    "    test_dependencies(\"minibatch_parse\", deps[2],\n",
    "                      (('only', 'ROOT'), ('only', 'arcs'), ('only', 'left')))\n",
    "    test_dependencies(\"minibatch_parse\", deps[3],\n",
    "                      (('again', 'ROOT'), ('again', 'arcs'), ('again', 'left'), ('again', 'only')))\n",
    "\n",
    "    # Out-of-bound test\n",
    "    sentences = [[\"right\"]]\n",
    "    deps = minibatch_parse(sentences, DummyModel(), 2)\n",
    "    test_dependencies(\"minibatch_parse\", deps[0], (('ROOT', 'right'),))\n",
    "\n",
    "    # Mixed arcs test\n",
    "    sentences = [[\"this\", \"is\", \"interleaving\", \"dependency\", \"test\"]]\n",
    "    deps = minibatch_parse(sentences, DummyModel(mode=\"interleave\"), 1)\n",
    "    test_dependencies(\"minibatch_parse\", deps[0],\n",
    "                      (('ROOT', 'is'), ('dependency', 'interleaving'),\n",
    "                      ('dependency', 'test'), ('is', 'dependency'), ('is', 'this')))\n",
    "    print(\"minibatch_parse test passed!\")\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     args = sys.argv\n",
    "#     if len(args) != 2:\n",
    "#         raise Exception(\"You did not provide a valid keyword. Either provide 'part_c' or 'part_d', when executing this script\")\n",
    "#     elif args[1] == \"part_c\":\n",
    "#         test_parse_step()\n",
    "#         test_parse()\n",
    "#     elif args[1] == \"part_d\":\n",
    "#         test_minibatch_parse()\n",
    "#     else:\n",
    "#         raise Exception(\"You did not provide a valid keyword. Either provide 'part_c' or 'part_d', when executing this script\")\n",
    "\n",
    "embeddings = np.zeros((100, 30), dtype=np.float32)\n",
    "model = ParserModel(embeddings)\n",
    "\n",
    "def check_embedding():\n",
    "    inds = torch.randint(0, 100, (4, 36), dtype=torch.long)\n",
    "    selected = model.embedding_lookup(inds)\n",
    "    assert np.all(selected.data.numpy() == 0), \"The result of embedding lookup: \" \\\n",
    "                                    + repr(selected) + \" contains non-zero elements.\"\n",
    "\n",
    "def check_forward():\n",
    "    inputs = torch.randint(0, 100, (4, 36), dtype=torch.long)\n",
    "    out = model(inputs)\n",
    "    expected_out_shape = (4, 3)\n",
    "    assert out.shape == expected_out_shape, \"The result shape of forward is: \" + repr(out.shape) + \\\n",
    "                                            \" which doesn't match expected \" + repr(expected_out_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "SHIFT test passed!\nLEFT-ARC test passed!\nRIGHT-ARC test passed!\nparse test passed!\n"
    }
   ],
   "source": [
    "test_parse_step()\n",
    "test_parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "check_forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "minibatch_parse test passed!\n"
    }
   ],
   "source": [
    "test_minibatch_parse()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}