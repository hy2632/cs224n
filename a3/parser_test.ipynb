{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
    }
   ],
   "source": [
    "from parser_transitions import *\n",
    "from parser_model import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_dependencies(name, deps, ex_deps):\n",
    "    \"\"\"Tests the provided dependencies match the expected dependencies\"\"\"\n",
    "    deps = tuple(sorted(deps))\n",
    "    assert deps == ex_deps, \\\n",
    "        \"{:} test resulted in dependency list {:}, expected {:}\".format(name, deps, ex_deps)\n",
    "\n",
    "\n",
    "def test_minibatch_parse():\n",
    "    \"\"\"Simple tests for the minibatch_parse function\n",
    "    Warning: these are not exhaustive\n",
    "    \"\"\"\n",
    "\n",
    "    # Unidirectional arcs test\n",
    "    sentences = [[\"right\", \"arcs\", \"only\"],\n",
    "                 [\"right\", \"arcs\", \"only\", \"again\"],\n",
    "                 [\"left\", \"arcs\", \"only\"],\n",
    "                 [\"left\", \"arcs\", \"only\", \"again\"]]\n",
    "    deps = minibatch_parse(sentences, DummyModel(), 2)\n",
    "    test_dependencies(\"minibatch_parse\", deps[0],\n",
    "                      (('ROOT', 'right'), ('arcs', 'only'), ('right', 'arcs')))\n",
    "    test_dependencies(\"minibatch_parse\", deps[1],\n",
    "                      (('ROOT', 'right'), ('arcs', 'only'), ('only', 'again'), ('right', 'arcs')))\n",
    "    test_dependencies(\"minibatch_parse\", deps[2],\n",
    "                      (('only', 'ROOT'), ('only', 'arcs'), ('only', 'left')))\n",
    "    test_dependencies(\"minibatch_parse\", deps[3],\n",
    "                      (('again', 'ROOT'), ('again', 'arcs'), ('again', 'left'), ('again', 'only')))\n",
    "\n",
    "    # Out-of-bound test\n",
    "    sentences = [[\"right\"]]\n",
    "    deps = minibatch_parse(sentences, DummyModel(), 2)\n",
    "    test_dependencies(\"minibatch_parse\", deps[0], (('ROOT', 'right'),))\n",
    "\n",
    "    # Mixed arcs test\n",
    "    sentences = [[\"this\", \"is\", \"interleaving\", \"dependency\", \"test\"]]\n",
    "    deps = minibatch_parse(sentences, DummyModel(mode=\"interleave\"), 1)\n",
    "    test_dependencies(\"minibatch_parse\", deps[0],\n",
    "                      (('ROOT', 'is'), ('dependency', 'interleaving'),\n",
    "                      ('dependency', 'test'), ('is', 'dependency'), ('is', 'this')))\n",
    "    print(\"minibatch_parse test passed!\")\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     args = sys.argv\n",
    "#     if len(args) != 2:\n",
    "#         raise Exception(\"You did not provide a valid keyword. Either provide 'part_c' or 'part_d', when executing this script\")\n",
    "#     elif args[1] == \"part_c\":\n",
    "#         test_parse_step()\n",
    "#         test_parse()\n",
    "#     elif args[1] == \"part_d\":\n",
    "#         test_minibatch_parse()\n",
    "#     else:\n",
    "#         raise Exception(\"You did not provide a valid keyword. Either provide 'part_c' or 'part_d', when executing this script\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "SHIFT test passed!\nLEFT-ARC test passed!\nRIGHT-ARC test passed!\nparse test passed!\n"
    }
   ],
   "source": [
    "test_parse_step()\n",
    "test_parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "    embeddings = np.zeros((100, 30), dtype=np.float32)\n",
    "    model = ParserModel(embeddings)\n",
    "\n",
    "    def check_embedding():\n",
    "        inds = torch.randint(0, 100, (4, 36), dtype=torch.long)\n",
    "        selected = model.embedding_lookup(inds)\n",
    "        assert np.all(selected.data.numpy() == 0), \"The result of embedding lookup: \" \\\n",
    "                                      + repr(selected) + \" contains non-zero elements.\"\n",
    "\n",
    "    def check_forward():\n",
    "        inputs = torch.randint(0, 100, (4, 36), dtype=torch.long)\n",
    "        out = model(inputs)\n",
    "        expected_out_shape = (4, 3)\n",
    "        assert out.shape == expected_out_shape, \"The result shape of forward is: \" + repr(out.shape) + \\\n",
    "                                                \" which doesn't match expected \" + repr(expected_out_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "1D tensors expected, got 2D, 2D tensors at /opt/conda/conda-bld/pytorch_1591914855613/work/aten/src/TH/generic/THTensorEvenMoreMath.cpp:431",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-123-dfa6695b84f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcheck_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-115-2746c93a2993>\u001b[0m in \u001b[0;36mcheck_forward\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcheck_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m36\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mexpected_out_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mexpected_out_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"The result shape of forward is: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/a3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cs224n/a3/parser_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, w)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;31m# x: (batch_size, n_features*embed_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;31m# self.embed_to_hidden_weight: (n_features*embed_size, hidden_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_to_hidden_weight\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_to_hidden_bias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_to_logits_weight\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_to_logits_bias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;31m### END YOUR CODE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: 1D tensors expected, got 2D, 2D tensors at /opt/conda/conda-bld/pytorch_1591914855613/work/aten/src/TH/generic/THTensorEvenMoreMath.cpp:431"
     ]
    }
   ],
   "source": [
    "check_forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0\n['ROOT', 'right'] ['arcs', 'only'] []\n\n\n1\n['ROOT', 'right'] ['arcs', 'only', 'again'] []\n\n\n2\n['ROOT'] ['left', 'arcs', 'only'] []\n\n\n3\n['ROOT'] ['left', 'arcs', 'only', 'again'] []\n\n\n0\n['ROOT', 'right', 'arcs'] ['only'] []\n\n\n1\n['ROOT', 'right', 'arcs'] ['only', 'again'] []\n\n\n2\n['ROOT'] ['left', 'arcs', 'only'] []\n\n\n3\n['ROOT'] ['left', 'arcs', 'only', 'again'] []\n\n\n0\n['ROOT', 'right', 'arcs', 'only'] [] []\n\n\n1\n['ROOT', 'right', 'arcs', 'only'] ['again'] []\n\n\n2\n['ROOT'] ['left', 'arcs', 'only'] []\n\n\n3\n['ROOT'] ['left', 'arcs', 'only', 'again'] []\n\n\n0\n['ROOT', 'right', 'arcs'] [] [('arcs', 'only')]\n\n\n1\n['ROOT', 'right', 'arcs', 'only', 'again'] [] []\n\n\n2\n['ROOT'] ['left', 'arcs', 'only'] []\n\n\n3\n['ROOT'] ['left', 'arcs', 'only', 'again'] []\n\n\n0\n['ROOT', 'right'] [] [('arcs', 'only'), ('right', 'arcs')]\n\n\n1\n['ROOT', 'right', 'arcs', 'only'] [] [('only', 'again')]\n\n\n2\n['ROOT'] ['left', 'arcs', 'only'] []\n\n\n3\n['ROOT'] ['left', 'arcs', 'only', 'again'] []\n\n\n0\n['ROOT'] [] [('arcs', 'only'), ('right', 'arcs'), ('ROOT', 'right')]\n\n\n"
    },
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-116-fe186d04477c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_minibatch_parse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-114-f4e13bde7db5>\u001b[0m in \u001b[0;36mtest_minibatch_parse\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m                  \u001b[0;34m[\u001b[0m\u001b[0;34m\"left\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"arcs\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"only\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                  [\"left\", \"arcs\", \"only\", \"again\"]]\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mdeps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mminibatch_parse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDummyModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     test_dependencies(\"minibatch_parse\", deps[0],\n\u001b[1;32m     20\u001b[0m                       (('ROOT', 'right'), ('arcs', 'only'), ('right', 'arcs')))\n",
      "\u001b[0;32m~/cs224n/a3/parser_transitions.py\u001b[0m in \u001b[0;36mminibatch_parse\u001b[0;34m(sentences, model, batch_size)\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munfinished_parses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m&\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munfinished_parses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m                 \u001b[0mdependencies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munfinished_parses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdependencies\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m                 \u001b[0munfinished_parses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munfinished_parses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0munfinished_parses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    }
   ],
   "source": [
    "test_minibatch_parse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Currently we couldn't totally implement the function because we need to implement the right model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = torch.tensor(np.zeros((100, 30), dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds = torch.randint(0, 100, (4, 36), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[48, 27, 86, 82, 82, 22, 38, 37,  2, 53, 99,  1, 78, 47, 33, 26, 25, 29,\n         27, 91, 54, 11, 72, 59, 63, 41, 86, 99, 44, 71, 51,  9, 53, 82, 24, 36],\n        [ 7, 46, 28, 36, 79, 92, 96, 24, 52, 53, 11, 93, 48, 59, 79, 52, 88, 91,\n         38,  5, 79, 19, 73, 72, 55, 74, 10, 63, 27, 30, 58,  9, 90, 85, 96, 56],\n        [53, 62, 20, 22, 20, 86, 89, 78, 36, 66, 55, 86, 76, 37, 27, 50, 51, 39,\n         90, 60, 36,  4, 21, 26, 51,  6, 22,  8, 99, 29, 58, 78, 97, 25, 19, 23],\n        [79,  7, 38, 73, 36, 10, 95, 39, 89, 49, 87, 16, 98, 89, 32, 29,  1, 76,\n         96,  9, 26, 66, 85, 21, 74, 72, 44, 50, 61, 82, 81,  3,  2, 52,  5, 32]])"
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "source": [
    "inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(torch.Size([100, 30]), torch.Size([4, 36]))"
     },
     "metadata": {},
     "execution_count": 74
    }
   ],
   "source": [
    "embeddings.shape, inds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(4, 1080)"
     },
     "metadata": {},
     "execution_count": 99
    }
   ],
   "source": [
    "4, 36*30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x1 = torch.index_select(embeddings, 0, inds[0]).flatten()\n",
    "x2 = torch.index_select(embeddings, 0, inds[1]).flatten()\n",
    "x3 = torch.index_select(embeddings, 0, inds[2]).flatten()\n",
    "x4 = torch.index_select(embeddings, 0, inds[3]).flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([4, 1080])"
     },
     "metadata": {},
     "execution_count": 96
    }
   ],
   "source": [
    "torch.stack((x1,x2,x3,x4), dim=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.]])"
     },
     "metadata": {},
     "execution_count": 110
    }
   ],
   "source": [
    "torch.stack([torch.index_select(embeddings, 0, inds[i]).flatten() for i in range (inds.shape[0])], dim=0)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}