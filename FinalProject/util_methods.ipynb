{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1596838379097",
   "display_name": "Python 3.6.11 64-bit ('squad': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gpu_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_available_devices():\n",
    "    \"\"\"Get IDs of all available GPUs.\n",
    "\n",
    "    Returns:\n",
    "        device (torch.device): Main device (GPU 0 or CPU).\n",
    "        gpu_ids (list): List of IDs of all GPUs that are available.\n",
    "    \"\"\"\n",
    "    gpu_ids = []\n",
    "    if torch.cuda.is_available():\n",
    "        gpu_ids += [gpu_id for gpu_id in range(torch.cuda.device_count())]\n",
    "        device = torch.device(f'cuda:{gpu_ids[0]}')\n",
    "        torch.cuda.set_device(device)\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "\n",
    "    return device, gpu_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(device(type='cuda', index=0), [0])"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "get_available_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## npz 文件的用法？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"data/test.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(examples):\n",
    "    \"\"\"Create batch tensors from a list of individual examples returned\n",
    "    by `SQuAD.__getitem__`. Merge examples of different length by padding\n",
    "    all examples to the maximum length in the batch.\n",
    "\n",
    "    Args:\n",
    "        examples (list): List of tuples of the form (context_idxs, context_char_idxs,\n",
    "        question_idxs, question_char_idxs, y1s, y2s, ids).\n",
    "\n",
    "    Returns:\n",
    "        examples (tuple): Tuple of tensors (context_idxs, context_char_idxs, question_idxs,\n",
    "        question_char_idxs, y1s, y2s, ids). All of shape (batch_size, ...), where\n",
    "        the remaining dimensions are the maximum length of examples in the input.\n",
    "\n",
    "    Adapted from:\n",
    "        https://github.com/yunjey/seq2seq-dataloader\n",
    "    \"\"\"\n",
    "    def merge_0d(scalars, dtype=torch.int64):\n",
    "        return torch.tensor(scalars, dtype=dtype)\n",
    "\n",
    "    def merge_1d(arrays, dtype=torch.int64, pad_value=0):\n",
    "        lengths = [(a != pad_value).sum() for a in arrays]\n",
    "        padded = torch.zeros(len(arrays), max(lengths), dtype=dtype)\n",
    "        for i, seq in enumerate(arrays):\n",
    "            end = lengths[i]\n",
    "            padded[i, :end] = seq[:end]\n",
    "        return padded\n",
    "\n",
    "    def merge_2d(matrices, dtype=torch.int64, pad_value=0):\n",
    "        heights = [(m.sum(1) != pad_value).sum() for m in matrices]\n",
    "        widths = [(m.sum(0) != pad_value).sum() for m in matrices]\n",
    "        padded = torch.zeros(len(matrices), max(heights), max(widths), dtype=dtype)\n",
    "        for i, seq in enumerate(matrices):\n",
    "            height, width = heights[i], widths[i]\n",
    "            padded[i, :height, :width] = seq[:height, :width]\n",
    "        return padded\n",
    "\n",
    "    # Group by tensor type\n",
    "    context_idxs, context_char_idxs, \\\n",
    "        question_idxs, question_char_idxs, \\\n",
    "        y1s, y2s, ids = zip(*examples)\n",
    "\n",
    "    # Merge into batch tensors\n",
    "    context_idxs = merge_1d(context_idxs)\n",
    "    context_char_idxs = merge_2d(context_char_idxs)\n",
    "    question_idxs = merge_1d(question_idxs)\n",
    "    question_char_idxs = merge_2d(question_char_idxs)\n",
    "    y1s = merge_0d(y1s)\n",
    "    y2s = merge_0d(y2s)\n",
    "    ids = merge_0d(ids)\n",
    "\n",
    "    return (context_idxs, context_char_idxs,\n",
    "            question_idxs, question_char_idxs,\n",
    "            y1s, y2s, ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 7, got 3)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-53d5620118e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-27-64cb71994639>\u001b[0m in \u001b[0;36mcollate_fn\u001b[0;34m(examples)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mcontext_idxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_char_idxs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mquestion_idxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestion_char_idxs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0my1s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my2s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;31m# Merge into batch tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 7, got 3)"
     ]
    }
   ],
   "source": [
    "collate_fn(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "\n",
    "class SQuAD(data.Dataset):\n",
    "    \"\"\"Stanford Question Answering Dataset (SQuAD).\n",
    "\n",
    "    Each item in the dataset is a tuple with the following entries (in order):\n",
    "        - context_idxs: Indices of the words in the context.\n",
    "            Shape (context_len,).\n",
    "        - context_char_idxs: Indices of the characters in the context.\n",
    "            Shape (context_len, max_word_len).\n",
    "        - question_idxs: Indices of the words in the question.\n",
    "            Shape (question_len,).\n",
    "        - question_char_idxs: Indices of the characters in the question.\n",
    "            Shape (question_len, max_word_len).\n",
    "        - y1: Index of word in the context where the answer begins.\n",
    "            -1 if no answer.\n",
    "        - y2: Index of word in the context where the answer ends.\n",
    "            -1 if no answer.\n",
    "        - id: ID of the example.\n",
    "\n",
    "    Args:\n",
    "        data_path (str): Path to .npz file containing pre-processed dataset.\n",
    "        use_v2 (bool): Whether to use SQuAD 2.0 questions. Otherwise only use SQuAD 1.1.\n",
    "    \"\"\"\n",
    "    def __init__(self, data_path, use_v2=True):\n",
    "        super(SQuAD, self).__init__()\n",
    "\n",
    "        dataset = np.load(data_path)\n",
    "        self.context_idxs = torch.from_numpy(dataset['context_idxs']).long()\n",
    "        self.context_char_idxs = torch.from_numpy(dataset['context_char_idxs']).long()\n",
    "        self.question_idxs = torch.from_numpy(dataset['ques_idxs']).long()\n",
    "        self.question_char_idxs = torch.from_numpy(dataset['ques_char_idxs']).long()\n",
    "        self.y1s = torch.from_numpy(dataset['y1s']).long()\n",
    "        self.y2s = torch.from_numpy(dataset['y2s']).long()\n",
    "\n",
    "        if use_v2:\n",
    "            # SQuAD 2.0: Use index 0 for no-answer token (token 1 = OOV)\n",
    "            batch_size, c_len, w_len = self.context_char_idxs.size()\n",
    "            ones = torch.ones((batch_size, 1), dtype=torch.int64)\n",
    "            self.context_idxs = torch.cat((ones, self.context_idxs), dim=1)\n",
    "            self.question_idxs = torch.cat((ones, self.question_idxs), dim=1)\n",
    "\n",
    "            ones = torch.ones((batch_size, 1, w_len), dtype=torch.int64)\n",
    "            self.context_char_idxs = torch.cat((ones, self.context_char_idxs), dim=1)\n",
    "            self.question_char_idxs = torch.cat((ones, self.question_char_idxs), dim=1)\n",
    "\n",
    "            self.y1s += 1\n",
    "            self.y2s += 1\n",
    "\n",
    "        # SQuAD 1.1: Ignore no-answer examples\n",
    "        self.ids = torch.from_numpy(dataset['ids']).long()\n",
    "        self.valid_idxs = [idx for idx in range(len(self.ids))\n",
    "                           if use_v2 or self.y1s[idx].item() >= 0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        idx = self.valid_idxs[idx]\n",
    "        example = (self.context_idxs[idx],\n",
    "                   self.context_char_idxs[idx],\n",
    "                   self.question_idxs[idx],\n",
    "                   self.question_char_idxs[idx],\n",
    "                   self.y1s[idx],\n",
    "                   self.y2s[idx],\n",
    "                   self.ids[idx])\n",
    "\n",
    "        return example\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.valid_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata = SQuAD(\"data/test.npz\", use_v2=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[(5915, 1000),\n (5915, 1000, 16),\n (5915, 100),\n (5915, 100, 16),\n (5915,),\n (5915,),\n (5915,)]"
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "testdata_np = np.load(\"data/test.npz\")\n",
    "[testdata_np[i].shape for i in testdata_np.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_tensors_padded = collate_fn(testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[torch.Size([5915, 414]),\n torch.Size([5915, 414, 16]),\n torch.Size([5915, 40]),\n torch.Size([5915, 40, 16]),\n torch.Size([5915]),\n torch.Size([5915]),\n torch.Size([5915])]"
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "[i.size() for i in batch_tensors_padded]"
   ]
  }
 ]
}