{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1596927859861",
   "display_name": "Python 3.6.11 64-bit ('squad': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gpu_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_available_devices():\n",
    "    \"\"\"Get IDs of all available GPUs.\n",
    "\n",
    "    Returns:\n",
    "        device (torch.device): Main device (GPU 0 or CPU).\n",
    "        gpu_ids (list): List of IDs of all GPUs that are available.\n",
    "    \"\"\"\n",
    "    gpu_ids = []\n",
    "    if torch.cuda.is_available():\n",
    "        gpu_ids += [gpu_id for gpu_id in range(torch.cuda.device_count())]\n",
    "        device = torch.device(f'cuda:{gpu_ids[0]}')\n",
    "        torch.cuda.set_device(device)\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "\n",
    "    return device, gpu_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(device(type='cpu'), [])"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "get_available_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## npz 文件的用法？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"data/test.npz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## class SQuAD\n",
    "\n",
    "- SQuAD类继承自torch.utils.data.Dataset\n",
    "- 初始化参数包括data_path和use_v2(bool)\n",
    "- 功能是把np.load(\"?.npz\")的一个dict转化为类。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "\n",
    "class SQuAD(data.Dataset):\n",
    "    \"\"\"Stanford Question Answering Dataset (SQuAD).\n",
    "\n",
    "    Each item in the dataset is a tuple with the following entries (in order):\n",
    "        - context_idxs: Indices of the words in the context.\n",
    "            Shape (context_len,).\n",
    "        - context_char_idxs: Indices of the characters in the context.\n",
    "            Shape (context_len, max_word_len).\n",
    "        - question_idxs: Indices of the words in the question.\n",
    "            Shape (question_len,).\n",
    "        - question_char_idxs: Indices of the characters in the question.\n",
    "            Shape (question_len, max_word_len).\n",
    "        - y1: Index of word in the context where the answer begins.\n",
    "            -1 if no answer.\n",
    "        - y2: Index of word in the context where the answer ends.\n",
    "            -1 if no answer.\n",
    "        - id: ID of the example.\n",
    "\n",
    "    Args:\n",
    "        data_path (str): Path to .npz file containing pre-processed dataset.\n",
    "        use_v2 (bool): Whether to use SQuAD 2.0 questions. Otherwise only use SQuAD 1.1.\n",
    "    \"\"\"\n",
    "    def __init__(self, data_path, use_v2=True):\n",
    "        super(SQuAD, self).__init__()\n",
    "\n",
    "        dataset = np.load(data_path)\n",
    "        self.context_idxs = torch.from_numpy(dataset['context_idxs']).long()\n",
    "        self.context_char_idxs = torch.from_numpy(dataset['context_char_idxs']).long()\n",
    "        self.question_idxs = torch.from_numpy(dataset['ques_idxs']).long()\n",
    "        self.question_char_idxs = torch.from_numpy(dataset['ques_char_idxs']).long()\n",
    "        self.y1s = torch.from_numpy(dataset['y1s']).long()\n",
    "        self.y2s = torch.from_numpy(dataset['y2s']).long()\n",
    "\n",
    "        if use_v2:\n",
    "            # SQuAD 2.0: Use index 0 for no-answer token (token 1 = OOV)\n",
    "            batch_size, c_len, w_len = self.context_char_idxs.size()\n",
    "            ones = torch.ones((batch_size, 1), dtype=torch.int64)\n",
    "            self.context_idxs = torch.cat((ones, self.context_idxs), dim=1)\n",
    "            self.question_idxs = torch.cat((ones, self.question_idxs), dim=1)\n",
    "\n",
    "            ones = torch.ones((batch_size, 1, w_len), dtype=torch.int64)\n",
    "            self.context_char_idxs = torch.cat((ones, self.context_char_idxs), dim=1)\n",
    "            self.question_char_idxs = torch.cat((ones, self.question_char_idxs), dim=1)\n",
    "\n",
    "            self.y1s += 1\n",
    "            self.y2s += 1\n",
    "\n",
    "        # SQuAD 1.1: Ignore no-answer examples\n",
    "        self.ids = torch.from_numpy(dataset['ids']).long()\n",
    "        self.valid_idxs = [idx for idx in range(len(self.ids))\n",
    "                           if use_v2 or self.y1s[idx].item() >= 0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        idx = self.valid_idxs[idx]\n",
    "        example = (self.context_idxs[idx],\n",
    "                   self.context_char_idxs[idx],\n",
    "                   self.question_idxs[idx],\n",
    "                   self.question_char_idxs[idx],\n",
    "                   self.y1s[idx],\n",
    "                   self.y2s[idx],\n",
    "                   self.ids[idx])\n",
    "\n",
    "        return example\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.valid_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "devdata = SQuAD(\"data/dev.npz\", use_v2=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([35, 22, 56,  ...,  0,  0,  0])"
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "devdata.y1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[(5951, 400),\n (5951, 400, 16),\n (5951, 50),\n (5951, 50, 16),\n (5951,),\n (5951,),\n (5951,)]"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "devdata_np = np.load(\"data/dev.npz\")\n",
    "[devdata_np[i].shape for i in devdata_np.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['context_idxs',\n 'context_char_idxs',\n 'ques_idxs',\n 'ques_char_idxs',\n 'y1s',\n 'y2s',\n 'ids']"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "list(devdata_np.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "34"
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "devdata_np['y2s'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[64,  6,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n       [14, 48, 17, 19,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n       [ 7,  5, 43,  6, 19, 18,  4,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n       [10, 11,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n       [30,  5, 18, 34, 17,  6, 42,  4,  0,  0,  0,  0,  0,  0,  0,  0],\n       [12,  5,  7, 17, 19,  3, 42,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n       [63,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]],\n      dtype=int32)"
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "# 第0个句子，7个单词，单词最大长度设置为16\n",
    "devdata_np['ques_char_idxs'][0][:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n        [64,  6,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n        [14, 48, 17, 19,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n        [ 7,  5, 43,  6, 19, 18,  4,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n        [10, 11,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n        [30,  5, 18, 34, 17,  6, 42,  4,  0,  0,  0,  0,  0,  0,  0,  0],\n        [12,  5,  7, 17, 19,  3, 42,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n        [63,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])"
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "# use_v2 = True, 增加第一个OOV\n",
    "devdata.question_char_idxs[0][:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "5951"
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "devdata.__len__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(examples):\n",
    "    \"\"\"Create batch tensors from a list of individual examples returned\n",
    "    by `SQuAD.__getitem__`. Merge examples of different length by padding\n",
    "    all examples to the maximum length in the batch.\n",
    "\n",
    "    Args:\n",
    "        examples (list): List of tuples of the form (context_idxs, context_char_idxs,\n",
    "        question_idxs, question_char_idxs, y1s, y2s, ids).\n",
    "\n",
    "    Returns:\n",
    "        examples (tuple): Tuple of tensors (context_idxs, context_char_idxs, question_idxs,\n",
    "        question_char_idxs, y1s, y2s, ids). All of shape (batch_size, ...), where\n",
    "        the remaining dimensions are the maximum length of examples in the input.\n",
    "\n",
    "    Adapted from:\n",
    "        https://github.com/yunjey/seq2seq-dataloader\n",
    "    \"\"\"\n",
    "    def merge_0d(scalars, dtype=torch.int64):\n",
    "        return torch.tensor(scalars, dtype=dtype)\n",
    "\n",
    "    def merge_1d(arrays, dtype=torch.int64, pad_value=0):\n",
    "        lengths = [(a != pad_value).sum() for a in arrays]\n",
    "        padded = torch.zeros(len(arrays), max(lengths), dtype=dtype)\n",
    "        for i, seq in enumerate(arrays):\n",
    "            end = lengths[i]\n",
    "            padded[i, :end] = seq[:end]\n",
    "        return padded\n",
    "\n",
    "    def merge_2d(matrices, dtype=torch.int64, pad_value=0):\n",
    "        heights = [(m.sum(1) != pad_value).sum() for m in matrices]\n",
    "        widths = [(m.sum(0) != pad_value).sum() for m in matrices]\n",
    "        padded = torch.zeros(len(matrices), max(heights), max(widths), dtype=dtype)\n",
    "        for i, seq in enumerate(matrices):\n",
    "            height, width = heights[i], widths[i]\n",
    "            padded[i, :height, :width] = seq[:height, :width]\n",
    "        return padded\n",
    "\n",
    "    # Group by tensor type\n",
    "    context_idxs, context_char_idxs, \\\n",
    "        question_idxs, question_char_idxs, \\\n",
    "        y1s, y2s, ids = zip(*examples)\n",
    "\n",
    "    # Merge into batch tensors\n",
    "    context_idxs = merge_1d(context_idxs)\n",
    "    context_char_idxs = merge_2d(context_char_idxs)\n",
    "    question_idxs = merge_1d(question_idxs)\n",
    "    question_char_idxs = merge_2d(question_char_idxs)\n",
    "    y1s = merge_0d(y1s)\n",
    "    y2s = merge_0d(y2s)\n",
    "    ids = merge_0d(ids)\n",
    "\n",
    "    return (context_idxs, context_char_idxs,\n",
    "            question_idxs, question_char_idxs,\n",
    "            y1s, y2s, ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_tensors_padded = collate_fn(testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[torch.Size([5915, 414]),\n torch.Size([5915, 414, 16]),\n torch.Size([5915, 40]),\n torch.Size([5915, 40, 16]),\n torch.Size([5915]),\n torch.Size([5915]),\n torch.Size([5915])]"
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "[i.size() for i in batch_tensors_padded]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "example1 = (1, \"str\", [3])\n",
    "example2 = (2, \"str2\", [100])\n",
    "examples = (example1, example2)\n",
    "ints, strs, lists = zip(*examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "((1, 2), ('str', 'str2'), ([3], [100]))"
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "source": [
    "ints, strs, lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'weight': Parameter containing:\n tensor([[-0.4117, -0.4105, -0.2888,  0.0490,  0.0045],\n         [ 0.3999,  0.0009,  0.1255, -0.4044,  0.2461],\n         [ 0.2509,  0.1652,  0.1981, -0.3752, -0.3934],\n         [ 0.4258,  0.0363,  0.0656,  0.2169, -0.1024]], requires_grad=True),\n 'bias': Parameter containing:\n tensor([-0.1324, -0.4426,  0.3663,  0.3982], requires_grad=True)}"
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "source": [
    "model = torch.nn.Linear(5,4)\n",
    "dict(model.named_parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = logging.Logger(\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "b\n"
    }
   ],
   "source": [
    "log.warning(\"b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取model类名称"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'Linear'"
     },
     "metadata": {},
     "execution_count": 81
    }
   ],
   "source": [
    "model.__class__.__name__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'/data/1.tar'"
     },
     "metadata": {},
     "execution_count": 89
    }
   ],
   "source": [
    "os.path.join(\"/data\", \"1.tar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## discretize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[1., 1., 1., 1., 0.],\n        [0., 1., 1., 1., 1.],\n        [0., 0., 1., 1., 1.],\n        [0., 0., 0., 1., 1.],\n        [0., 0., 0., 0., 1.]])"
     },
     "metadata": {},
     "execution_count": 108
    }
   ],
   "source": [
    "c_len = 5\n",
    "is_legal_pair = torch.triu(torch.ones((c_len, c_len)))\n",
    "max_len = 4\n",
    "is_legal_pair -= torch.triu(torch.ones((c_len, c_len)), diagonal=max_len)\n",
    "is_legal_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_legal_pair = torch.triu(torch.ones((c_len, c_len)), diagonal = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[[-0.0000,  0.0000, -1.2679,  1.3683,  0.3288],\n         [ 0.0000, -0.0000, -0.0000, -0.3547,  1.1280],\n         [-0.0000, -0.0000,  0.0000, -0.0000,  1.1315],\n         [-0.0000,  0.0000,  0.0000, -0.0000, -0.0000],\n         [-0.0000,  0.0000, -0.0000,  0.0000, -0.0000]],\n\n        [[-0.0000,  0.0000, -0.3493,  0.3470, -1.1746],\n         [ 0.0000,  0.0000,  0.0000, -1.5943, -0.3677],\n         [ 0.0000, -0.0000,  0.0000, -0.0000, -2.3150],\n         [-0.0000, -0.0000,  0.0000, -0.0000,  0.0000],\n         [-0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n\n        [[ 0.0000,  0.0000,  1.5740,  0.0476,  0.5404],\n         [ 0.0000,  0.0000,  0.0000, -0.5221,  0.6724],\n         [-0.0000,  0.0000, -0.0000,  0.0000, -0.1659],\n         [-0.0000,  0.0000,  0.0000, -0.0000, -0.0000],\n         [ 0.0000, -0.0000, -0.0000,  0.0000,  0.0000]]])"
     },
     "metadata": {},
     "execution_count": 128
    }
   ],
   "source": [
    "p_joint = torch.randn((3, 5, 5))\n",
    "p_joint *= is_legal_pair\n",
    "p_joint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_in_row = torch.max(p_joint, dim = 2)[0]\n",
    "max_in_col = torch.max(p_joint, dim = 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([3, 3, 2])"
     },
     "metadata": {},
     "execution_count": 139
    }
   ],
   "source": [
    "torch.argmax(max_in_col, dim=-1)"
   ]
  }
 ]
}