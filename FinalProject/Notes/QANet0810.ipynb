{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1597186742121",
   "display_name": "Python 3.6.10 64-bit ('squad': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, seq_len, word_len, char_dim = 10, 11, 16, 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([10, 11, 20])"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "char_emb = torch.randn(batch_size, seq_len, word_len, char_dim)\n",
    "char_emb, _ = torch.max(char_emb, dim=2, keepdim=True)\n",
    "char_emb = char_emb.squeeze(dim=2)\n",
    "char_emb.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = nn.Conv1d(500, 128, 7, padding = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(10, 100, 500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([10, 128, 100])"
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "conv(x.permute(0,2,1)).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n        [-0.0828,  0.6720, -0.1499,  ..., -0.1918, -0.3785, -0.0659],\n        ...,\n        [ 0.3990, -0.0185,  0.3715,  ...,  0.0370, -0.0975, -0.6882],\n        [-0.0652, -0.0192, -0.8155,  ...,  0.9371, -0.4975, -1.1756],\n        [ 0.5272, -1.0988, -0.3210,  ..., -0.0951, -0.1996, -1.2129]])"
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "source": [
    "import util\n",
    "word_vectors = util.torch_from_json(\"data/word_emb.json\")\n",
    "word_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([88714, 300])"
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "source": [
    "word_vectors.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[0., 0., 0., 0.]])"
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "source": [
    "torch.autograd.Variable(torch.zeros(1,4), requires_grad=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 字典反查"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {'a':0, 'b':0, 'c':1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{0: 'b', 1: 'c'}"
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "source": [
    "{value:key for key,value in dict.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 如果要保留重复的值进list？ 有点意思"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_dict = {}\n",
    "for key, value in dict.items():\n",
    "    if new_dict.get(value, False):\n",
    "        new_dict[value] = new_dict[value].append(key) if isinstance(new_dict[value],list) else [new_dict[value], key]\n",
    "    else:\n",
    "        new_dict[value] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{0: ['a', 'b'], 1: 'c'}"
     },
     "metadata": {},
     "execution_count": 72
    }
   ],
   "source": [
    "new_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 08/11维度检查"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from layers_QANet import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "posenc = PositionalEncoding(500, 0, 400)\n",
    "cnn_init = CNN(input_dim=500,\n",
    "                            kernel_size=7,\n",
    "                            padding=3,\n",
    "                            filters=128)\n",
    "cnn = CNN(input_dim=128,\n",
    "                       kernel_size=7,\n",
    "                       padding=3,\n",
    "                       filters=128)\n",
    "layernorm = LayerNorm(128)\n",
    "att = MultiHeadedAttention(h=8,\n",
    "                                        d_model=128,\n",
    "                                        dropout=0)\n",
    "ffn = FFN(input_dim=128,\n",
    "                       output_dim=128,\n",
    "                       dropout=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.zeros(3, 16, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([3, 16, 128])\ntorch.Size([3, 16, 128])\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([3, 16, 128])"
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "source": [
    "x = posenc(input)\n",
    "x = cnn_init(x)\n",
    "print(x.size())\n",
    "for i in range(4):\n",
    "    x += cnn(layernorm(x))\n",
    "\n",
    "q = layernorm(x)\n",
    "print(q.size())\n",
    "x += att(q, None)\n",
    "x += ffn(layernorm(x))\n",
    "\n",
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[(1, 2), (1, 2), (1, 2)]"
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": [
    "list(zip([1,1,1,1], [2,2,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = nn.Conv1d(\n",
    "            in_channels=500,\n",
    "            out_channels=128,\n",
    "            kernel_size=7,\n",
    "            padding=3,\n",
    "            bias=True,\n",
    "        )\n",
    "x = conv(input.permute(0,2,1)).permute(0,2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([3, 16, 128])"
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "source": [
    "conv = nn.Conv1d(\n",
    "            in_channels=128,\n",
    "            out_channels=128,\n",
    "            kernel_size=7,\n",
    "            padding=3,\n",
    "            bias=True,\n",
    "        )\n",
    "conv(x.permute(0,2,1)).permute(0,2,1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([64, 1, 1, 257])"
     },
     "metadata": {},
     "execution_count": 68
    }
   ],
   "source": [
    "torch.randn(64,257).unsqueeze(1).unsqueeze(1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "text": "\u001b[0;31mDocstring:\u001b[0m\nmasked_fill_(mask, value)\n\nFills elements of :attr:`self` tensor with :attr:`value` where :attr:`mask` is\nTrue. The shape of :attr:`mask` must be\n:ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\ntensor.\n\nArgs:\n    mask (BoolTensor): the boolean mask\n    value (float): the value to fill in with\n\u001b[0;31mType:\u001b[0m      method_descriptor\n"
    }
   ],
   "source": [
    "torch.Tensor.masked_fill_?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "5e-02, -1.0837e-01],\n          [-2.0799e-01, -2.8529e-01, -2.3916e-01,  ...,  1.3496e+00,\n            1.5313e-01,  4.5822e-01]]],\n\n\n        [[[-2.2337e-01, -8.0660e-01, -2.4637e-02,  ..., -1.2298e+00,\n           -2.9158e-01, -6.2693e-01],\n          [ 1.7014e+00,  2.0341e+00, -2.8929e+00,  ..., -9.5293e-01,\n            1.0984e+00,  5.4336e-01],\n          [-1.1239e+00, -1.2064e+00,  2.9586e-01,  ..., -4.4473e-02,\n           -5.2360e-01,  4.3700e-01],\n          ...,\n          [ 2.6286e-01,  1.0938e+00,  8.5633e-02,  ...,  3.4203e-01,\n            1.8694e-01, -5.0930e-01],\n          [ 1.9334e-01, -1.6825e-01,  1.3490e+00,  ...,  1.0281e+00,\n           -6.7471e-02,  4.3761e-01],\n          [ 8.7041e-01, -1.0954e+00,  2.7368e-01,  ...,  3.4801e-01,\n           -1.3121e+00,  6.4257e-01]],\n\n         [[-5.4967e-01,  6.5172e-01, -1.0226e-01,  ...,  1.4907e+00,\n            5.3949e-02, -1.5420e+00],\n          [ 5.5628e-01, -2.6444e-01, -9.1508e-01,  ...,  1.6519e+00,\n           -6.6285e-01, -2.8100e-01],\n          [-3.8473e-01, -2.1034e-02, -1.1907e+00,  ...,  9.2726e-01,\n            1.6192e+00,  1.2727e+00],\n          ...,\n          [ 2.1803e+00, -9.3786e-01,  9.3232e-01,  ..., -1.9106e+00,\n            1.2182e+00, -3.1456e-01],\n          [ 1.6311e+00, -2.0581e+00, -1.4954e+00,  ..., -7.8293e-01,\n           -1.1122e+00, -1.3489e-01],\n          [ 1.2929e+00, -8.0842e-01,  1.4831e-01,  ...,  5.8802e-01,\n           -4.6201e-02,  4.9965e-01]],\n\n         [[ 2.5788e+00,  1.5061e+00,  6.6749e-01,  ...,  8.0590e-01,\n            1.7563e-01, -1.5367e+00],\n          [-9.1463e-01,  1.2664e-01,  1.1711e-02,  ..., -1.4157e+00,\n           -1.9635e+00,  2.4665e-01],\n          [-3.3606e-01, -6.7889e-01, -9.5943e-02,  ..., -5.8399e-01,\n           -9.6592e-01,  9.8608e-01],\n          ...,\n          [-9.0679e-01, -1.4847e+00,  2.2702e-01,  ...,  1.1436e+00,\n            1.3925e+00,  9.8194e-01],\n          [-9.2079e-01,  1.0136e+00,  5.2704e-01,  ...,  2.3041e-01,\n           -8.4896e-01,  1.8656e-02],\n          [ 4.9598e-02, -2.0876e+00,  8.2144e-01,  ...,  1.8229e+00,\n           -6.5491e-02, -2.2620e-01]],\n\n         ...,\n\n         [[ 1.6119e+00, -6.9302e-01,  1.4303e-01,  ...,  9.2082e-02,\n            2.0636e-01, -2.2880e+00],\n          [-1.3290e+00,  7.4907e-01,  7.3476e-01,  ..., -3.6063e-01,\n            8.4143e-02, -2.0751e+00],\n          [ 6.1096e-01, -6.4650e-01, -1.3637e-01,  ..., -8.8233e-01,\n            2.5637e-01, -9.9847e-01],\n          ...,\n          [ 2.0870e-01, -2.2820e-01,  1.0595e+00,  ..., -9.2135e-01,\n           -2.9357e-01, -8.2630e-01],\n          [-2.5613e-01,  2.9668e+00, -1.0109e+00,  ...,  9.4223e-01,\n           -6.2209e-01,  8.1237e-01],\n          [ 1.9974e+00, -1.0815e+00, -1.1677e+00,  ...,  9.7701e-01,\n           -1.2252e+00, -9.1379e-01]],\n\n         [[ 1.1017e+00,  1.0599e+00,  4.5162e-01,  ..., -1.0127e+00,\n            4.2791e-01,  5.2115e-01],\n          [-2.2299e-01,  4.1295e-01, -8.8701e-01,  ..., -1.0226e+00,\n            8.7621e-01,  6.0291e-01],\n          [-1.4314e+00, -2.0180e+00,  8.1531e-01,  ..., -3.1921e-01,\n            6.7451e-01,  9.2001e-01],\n          ...,\n          [ 1.5373e+00,  7.8815e-01, -6.9055e-01,  ...,  2.4874e+00,\n            2.1770e-02,  2.3366e-01],\n          [ 4.6758e-01,  1.1257e+00,  2.6590e-01,  ..., -1.9347e+00,\n            6.2718e-01, -2.9539e-01],\n          [ 4.1797e-01, -7.3319e-01, -3.2144e-01,  ..., -6.4405e-01,\n           -4.7902e-02, -6.6437e-01]],\n\n         [[ 5.1544e-01, -3.8348e-01, -5.5626e-01,  ..., -1.0780e+00,\n            1.1324e+00,  7.8683e-01],\n          [-1.6536e-01,  1.3495e-01,  4.6274e-01,  ...,  1.0118e+00,\n           -1.1365e-01,  1.9100e-01],\n          [-1.3973e+00,  1.0257e-01,  5.4774e-03,  ..., -2.0727e-01,\n            1.0720e+00, -2.3401e+00],\n          ...,\n          [-3.1999e+00, -2.2294e+00,  9.1108e-01,  ..., -4.1486e-02,\n            4.7146e-01,  8.3530e-01],\n          [-1.0825e-01,  4.9789e-01,  1.8328e+00,  ...,  4.0234e-01,\n           -1.2174e+00, -1.8158e+00],\n          [-2.0502e+00, -5.8192e-01,  3.8511e-02,  ..., -9.9218e-01,\n            1.9030e+00, -2.1266e+00]]],\n\n\n        [[[ 1.1872e+00,  3.1438e-01,  1.0309e-01,  ...,  7.8065e-01,\n            2.7689e-01, -5.5798e-01],\n          [ 2.7274e-01,  4.4511e-01,  1.4998e-01,  ..., -9.4039e-01,\n           -1.4397e+00,  7.5466e-03],\n          [ 1.9753e-01, -7.8932e-01,  1.5388e-01,  ...,  1.7936e-01,\n            1.0631e+00, -6.9102e-01],\n          ...,\n          [ 8.3791e-01,  6.9802e-01,  3.6684e-01,  ..., -2.0580e-01,\n           -1.0510e+00, -8.5497e-01],\n          [ 7.7607e-01, -9.3865e-01, -1.3064e+00,  ..., -3.1575e-01,\n            1.7238e-01,  1.6030e+00],\n          [-9.9309e-02,  6.2853e-01, -8.3240e-01,  ..., -1.7704e+00,\n           -1.0969e+00, -3.1559e-01]],\n\n         [[-1.5114e-01, -1.3509e+00,  4.0532e-01,  ...,  4.0460e-01,\n            6.2243e-01, -1.2887e+00],\n          [-4.7617e-01, -4.4245e-01,  1.0135e+00,  ...,  7.2154e-01,\n            4.6085e-01,  1.5350e+00],\n          [-7.7528e-01, -9.1212e-01,  9.4017e-01,  ...,  3.1847e-01,\n            9.4622e-01,  3.8552e-01],\n          ...,\n          [ 3.6713e-01, -5.3911e-01, -1.3287e-01,  ...,  2.6710e+00,\n           -2.4511e-02, -3.7213e-01],\n          [ 1.2349e+00,  7.5903e-01, -2.8153e-01,  ..., -9.3162e-01,\n           -1.4960e+00,  2.5580e-01],\n          [-9.9877e-01, -9.8526e-01, -4.9347e-01,  ..., -1.0025e+00,\n            6.2214e-01, -7.1997e-01]],\n\n         [[ 3.7489e-01, -4.9668e-01,  1.0269e+00,  ...,  1.6564e+00,\n            4.3229e-01,  1.7976e-01],\n          [ 4.3636e-02,  2.9247e-03, -2.0523e-02,  ...,  1.7922e-01,\n            1.2988e+00,  1.2516e+00],\n          [ 2.1969e+00,  5.0503e-01, -2.9304e-01,  ..., -7.6439e-01,\n           -1.0548e+00,  1.0251e+00],\n          ...,\n          [-3.0013e-01,  1.9237e+00,  4.6437e-01,  ...,  3.2234e-02,\n            3.6380e-01,  1.2892e+00],\n          [-1.3175e+00,  4.8363e-01,  2.2980e-01,  ...,  3.7487e-01,\n            2.1312e+00,  1.3003e-02],\n          [ 5.4840e-01,  4.7798e-01, -1.7734e+00,  ..., -1.0650e+00,\n            1.4597e+00,  3.4319e+00]],\n\n         ...,\n\n         [[-8.9807e-01, -7.5143e-01,  9.3786e-01,  ..., -2.2902e-01,\n            1.5802e+00, -1.3743e+00],\n          [ 1.1644e-01, -9.8381e-01, -2.4258e+00,  ...,  1.3192e+00,\n           -1.5970e+00,  6.3154e-01],\n          [-2.1028e+00, -1.8270e+00,  9.0642e-01,  ...,  7.0758e-01,\n           -1.2892e-01,  5.6201e-01],\n          ...,\n          [-9.5801e-01, -1.4665e+00,  9.0055e-01,  ...,  1.3967e+00,\n            1.1030e+00,  1.5218e+00],\n          [ 5.5688e-01,  3.6350e-01, -1.0324e+00,  ...,  3.9697e-01,\n           -1.2665e+00, -5.2702e-01],\n          [ 7.5241e-01,  4.8793e-01, -3.1524e-01,  ..., -1.2613e+00,\n           -6.7258e-01, -1.3253e+00]],\n\n         [[ 8.5322e-01,  1.0206e+00,  5.2499e-01,  ...,  1.2108e-02,\n           -1.2795e+00,  7.8719e-01],\n          [-8.7834e-02,  1.9761e+00, -7.8143e-01,  ..., -5.2811e-01,\n           -1.4091e+00, -1.2900e+00],\n          [ 4.6769e-01, -8.5226e-01, -2.3806e+00,  ...,  5.4943e-01,\n            1.5219e-01, -2.8104e-01],\n          ...,\n          [ 6.3901e-01,  4.4984e-01, -1.7346e+00,  ...,  1.9911e+00,\n           -5.2051e-01, -1.3129e-01],\n          [ 6.2878e-01, -8.7449e-01,  1.8528e-01,  ..., -1.2424e+00,\n           -1.6595e+00,  1.4172e-01],\n          [-1.6347e-01, -4.2198e-01,  1.2629e+00,  ...,  7.9215e-01,\n           -2.3033e+00, -1.3039e+00]],\n\n         [[ 1.9980e+00,  6.3018e-01,  1.6130e-01,  ...,  1.1707e-01,\n           -6.2185e-03,  6.2001e-01],\n          [-9.1167e-01, -8.6138e-01, -4.6654e-01,  ...,  8.5606e-01,\n            3.2690e-01, -1.3678e+00],\n          [ 3.9590e-01,  3.3462e-01,  5.7307e-01,  ...,  7.7400e-01,\n            7.3353e-01,  6.7774e-01],\n          ...,\n          [ 1.1444e+00,  1.3228e+00,  1.1756e-01,  ...,  1.3987e+00,\n            1.1615e+00, -1.0819e+00],\n          [-2.3162e-01,  1.0102e+00,  5.2443e-01,  ...,  2.8856e-01,\n            1.1411e+00, -7.1054e-01],\n          [ 3.9236e-01,  1.8736e-02, -7.6788e-01,  ...,  2.1208e-02,\n            7.9994e-01, -3.5487e-01]]],\n\n\n        ...,\n\n\n        [[[ 5.2287e-02, -2.8698e-01, -1.0261e+00,  ...,  3.4133e-01,\n           -8.0974e-02,  1.1951e-01],\n          [ 2.2896e-01, -1.6100e+00, -2.4091e+00,  ..., -1.5849e+00,\n            2.8831e-01,  1.6295e-01],\n          [-4.0274e-02,  2.1001e+00,  1.5549e+00,  ...,  7.8114e-02,\n           -1.4628e-02, -1.7792e-01],\n          ...,\n          [ 1.1653e+00,  3.0864e-01, -1.1776e+00,  ...,  4.9080e-01,\n           -5.2809e-02, -1.9845e-01],\n          [ 2.6114e-02,  1.6239e-02,  1.6896e+00,  ...,  1.9409e+00,\n           -8.8653e-01,  8.3143e-01],\n          [ 2.0760e+00, -7.3401e-01, -4.3239e-02,  ...,  1.2574e+00,\n            1.7391e+00, -7.9969e-01]],\n\n         [[ 6.2048e-01, -1.6490e+00,  5.0768e-01,  ...,  1.1231e+00,\n            1.5372e+00, -1.5046e-03],\n          [ 1.5950e+00, -1.3677e-01,  5.0006e-02,  ...,  4.2898e-01,\n            8.8072e-01,  7.4484e-01],\n          [-7.3994e-01,  6.0041e-01,  2.0492e-02,  ..., -6.3838e-01,\n           -1.2431e+00,  1.4116e+00],\n          ...,\n          [-3.4030e-01, -1.4908e+00, -2.0965e+00,  ..., -1.8742e-01,\n            2.1596e+00,  7.5606e-01],\n          [ 2.8112e-01, -4.7579e-02,  3.5830e-01,  ...,  8.2048e-01,\n            2.3229e+00,  9.0153e-01],\n          [-7.8562e-01,  5.5086e-01,  1.3525e+00,  ...,  2.1261e+00,\n           -2.0202e+00, -7.8366e-01]],\n\n         [[-4.5191e-01, -5.3523e-01, -2.7328e-01,  ..., -3.4497e-01,\n           -3.6589e-01, -1.6824e+00],\n          [-4.1693e-01,  1.1739e+00, -2.7044e-01,  ..., -1.1699e-01,\n           -2.6049e-01, -4.9390e-01],\n          [-7.1827e-01,  1.3290e-01,  1.4475e+00,  ...,  4.2131e-01,\n           -2.6158e-01, -6.5265e-01],\n          ...,\n          [ 2.0142e-01, -1.3012e+00, -7.4983e-01,  ...,  8.7345e-02,\n            1.5581e+00,  1.7404e-01],\n          [-1.1386e+00, -1.0582e+00, -1.4320e+00,  ..., -1.1271e+00,\n           -6.5451e-01, -1.3040e-01],\n          [ 8.4922e-01,  2.3228e-01, -2.1548e-01,  ...,  2.8569e-01,\n            1.7198e+00, -4.7392e-01]],\n\n         ...,\n\n         [[-1.2727e+00,  5.3213e-01, -1.7491e+00,  ..., -1.2797e+00,\n           -5.3491e-01, -1.5777e+00],\n          [-3.2662e-01, -4.4870e-01, -5.1622e-01,  ..., -7.4210e-01,\n            1.1894e+00, -6.2270e-01],\n          [ 9.4202e-01, -3.7901e-01, -8.6096e-01,  ...,  1.0480e+00,\n           -1.5119e+00, -5.0722e-01],\n          ...,\n          [ 6.9336e-01, -2.6990e-02, -1.9207e+00,  ...,  1.0834e+00,\n            9.2846e-01, -1.1934e+00],\n          [-2.4248e+00,  1.3715e+00, -2.8839e-01,  ..., -6.4194e-01,\n           -1.5511e+00,  2.6439e-01],\n          [ 1.2548e-01,  2.9347e-01,  1.6332e+00,  ...,  1.2343e+00,\n           -1.2455e+00,  3.6877e-01]],\n\n         [[ 1.7419e+00, -6.4010e-02,  4.3698e-01,  ...,  8.0440e-02,\n           -7.4458e-01, -4.1776e-01],\n          [-2.4079e+00, -4.7817e-01, -6.7585e-01,  ...,  4.0022e-01,\n           -5.3020e-01, -6.5348e-02],\n          [-1.8490e-01, -1.0416e+00, -4.8839e-01,  ...,  7.1660e-01,\n           -6.5532e-01,  2.6038e-01],\n          ...,\n          [ 5.5726e-01,  8.9112e-01, -1.5157e+00,  ..., -9.1086e-01,\n           -1.6331e+00,  1.7152e+00],\n          [-6.7249e-01, -1.2211e+00,  7.8920e-01,  ..., -1.8206e-01,\n           -1.1815e+00, -1.1756e-01],\n          [-4.0696e-01, -3.6318e-02, -1.3226e+00,  ..., -1.2035e+00,\n           -9.5981e-01,  2.4014e-01]],\n\n         [[ 4.6106e-01, -4.0482e-01, -5.2541e-01,  ...,  1.6601e-01,\n            1.5604e+00, -4.6583e-01],\n          [-1.4355e+00,  1.3879e+00,  4.5330e-03,  ..., -4.0533e-01,\n           -3.8514e-01, -7.1900e-01],\n          [ 2.1054e+00,  5.7635e-01,  4.5533e-02,  ..., -1.5091e+00,\n            3.1742e+00,  2.4015e-02],\n          ...,\n          [-5.0119e-01,  1.6110e+00, -9.2658e-01,  ...,  1.1708e+00,\n            6.6333e-01,  9.5212e-01],\n          [ 1.3158e+00, -4.3506e-01,  1.1494e+00,  ..., -6.0151e-01,\n           -3.5911e-01,  4.8843e-01],\n          [-4.4625e-03, -5.5690e-01, -6.7240e-01,  ..., -6.4381e-01,\n           -2.2438e+00,  8.5690e-02]]],\n\n\n        [[[-4.4898e-01,  1.9022e+00,  4.2359e-01,  ...,  5.3172e-01,\n            1.8786e+00, -1.8110e+00],\n          [-7.6416e-01, -5.5886e-01,  1.5391e+00,  ..., -9.7952e-01,\n            1.7183e-01, -2.4452e-01],\n          [-6.2918e-01, -1.2750e+00, -1.5198e+00,  ..., -5.5815e-01,\n            1.2358e+00, -1.2974e+00],\n          ...,\n          [ 5.0203e-01,  1.5148e-01,  4.0618e-01,  ...,  1.7248e+00,\n           -1.7277e+00, -9.5808e-01],\n          [-2.7019e-01,  5.2051e-01, -2.1468e+00,  ..., -1.4864e+00,\n            1.3927e-01, -5.1576e-01],\n          [ 1.5686e+00,  5.6166e-01, -8.6087e-01,  ...,  9.3797e-01,\n           -1.9843e-01, -1.0446e-01]],\n\n         [[ 1.4758e+00, -1.6778e+00, -1.4815e-01,  ...,  8.4665e-01,\n           -1.8493e+00, -1.0640e-01],\n          [ 3.7600e-01,  1.1631e+00, -1.5498e+00,  ..., -2.2856e-01,\n            4.3659e-01,  2.3889e-01],\n          [-9.2356e-01, -3.5065e-01, -1.7467e+00,  ..., -2.2250e+00,\n            3.6334e-01,  7.2375e-01],\n          ...,\n          [ 1.6402e+00,  1.3537e+00,  3.3599e-01,  ..., -1.8897e-01,\n           -5.6386e-01,  2.8855e-01],\n          [-1.6129e-01,  4.9190e-01, -5.8475e-02,  ..., -3.3348e-01,\n            3.8152e-01, -1.1754e+00],\n          [ 4.1637e-01, -1.2917e+00, -1.7805e+00,  ..., -2.9362e+00,\n           -8.3081e-01,  1.7852e+00]],\n\n         [[ 5.9376e-02,  8.5829e-02,  2.1375e+00,  ...,  2.0011e+00,\n            5.7655e-01,  4.0247e-02],\n          [ 2.4831e-01, -1.8542e-01, -2.8911e-02,  ..., -4.8361e-01,\n            3.3177e-01,  5.2840e-01],\n          [ 1.0590e+00, -1.2594e+00,  7.4561e-01,  ..., -1.9600e-01,\n            1.4043e+00,  1.0448e+00],\n          ...,\n          [ 5.7843e-01,  4.2491e-01, -5.4247e-01,  ...,  1.0599e+00,\n           -1.9206e-01,  1.1214e+00],\n          [ 4.2685e-01,  9.6234e-01,  1.1475e+00,  ...,  1.0249e+00,\n           -1.3748e+00,  5.7794e-01],\n          [ 1.1916e-01,  1.2310e+00, -1.4047e+00,  ...,  2.1092e-01,\n            4.6316e-01, -3.9670e-01]],\n\n         ...,\n\n         [[-4.8850e-02,  1.1363e-02, -7.5991e-01,  ...,  6.2059e-01,\n            2.2869e+00, -1.3031e+00],\n          [ 3.7304e-01,  2.0656e-01, -6.5578e-01,  ...,  8.2281e-01,\n            8.4479e-01, -2.9141e+00],\n          [ 1.3202e+00, -2.5119e-01, -2.2077e-01,  ..., -7.2529e-01,\n            8.0476e-01,  1.8814e-01],\n          ...,\n          [-1.5764e+00,  4.0518e-01, -9.9617e-01,  ...,  5.8436e-01,\n            6.0461e-02, -1.0589e+00],\n          [-7.3146e-01, -1.1178e-01,  7.2574e-01,  ...,  1.2470e+00,\n            3.7531e-01,  4.7835e-01],\n          [ 5.2665e-01, -4.8553e-01,  9.5142e-03,  ...,  1.0233e+00,\n            3.7340e-01, -4.4823e-01]],\n\n         [[ 6.0767e-01,  1.5514e+00,  2.2514e+00,  ...,  2.2171e-01,\n           -1.4323e+00, -1.7779e+00],\n          [ 1.3960e-01, -1.0307e+00, -1.4515e+00,  ..., -1.2829e+00,\n           -7.5329e-01, -4.0068e-01],\n          [ 6.0425e-01, -3.5107e-01, -1.9817e+00,  ..., -4.4734e-01,\n            1.0798e+00,  8.6351e-01],\n          ...,\n          [-1.6967e+00, -1.1938e+00, -1.0607e+00,  ..., -1.1321e+00,\n           -2.6877e+00, -1.5180e+00],\n          [-1.2179e+00, -4.8657e-01, -1.1015e-01,  ...,  2.7631e-01,\n            4.0256e-01, -2.1636e+00],\n          [ 6.1680e-01,  9.9197e-01,  1.5062e+00,  ...,  2.1555e-01,\n           -1.7186e+00,  4.6208e-01]],\n\n         [[ 7.8762e-01,  9.0096e-01,  8.1456e-01,  ...,  4.0620e-01,\n           -6.3967e-01,  8.8204e-02],\n          [ 7.2856e-01, -7.1781e-02,  7.1806e-01,  ...,  6.4344e-01,\n            2.2420e+00,  1.7465e+00],\n          [ 2.8941e-01, -5.6016e-01,  1.5537e+00,  ...,  6.3251e-01,\n           -1.7650e+00, -8.5377e-01],\n          ...,\n          [ 7.6965e-01, -1.1589e+00,  8.6062e-01,  ...,  1.2377e+00,\n            5.0350e-01, -1.8343e-01],\n          [-6.3964e-01, -3.4411e-01,  7.6490e-01,  ...,  4.6595e-01,\n           -1.6147e+00, -1.7449e-01],\n          [ 1.2175e-01, -2.6729e-01,  6.2977e-01,  ..., -4.8670e-01,\n            3.8519e-01,  9.1450e-01]]],\n\n\n        [[[ 1.8549e-01, -6.3049e-01,  1.4364e-01,  ...,  7.7346e-01,\n           -1.6373e-01,  4.9912e-01],\n          [ 1.9010e-02, -2.4248e-01,  2.1320e-01,  ...,  4.2595e-01,\n            1.5534e+00, -1.7880e+00],\n          [-6.5270e-01,  9.0077e-01,  4.0050e-01,  ..., -5.3502e-01,\n           -1.0988e+00, -9.0886e-01],\n          ...,\n          [ 1.7863e-01, -3.8027e-01,  4.8752e-01,  ..., -2.0976e-02,\n           -1.6115e+00,  1.1568e+00],\n          [ 2.0310e+00,  1.1854e-01,  9.0861e-02,  ...,  9.5449e-01,\n           -5.7998e-01, -1.2850e+00],\n          [ 1.2949e+00,  7.1224e-02, -7.5318e-01,  ..., -1.3405e-01,\n           -5.9061e-01, -3.2842e-01]],\n\n         [[ 3.9765e-01, -2.4097e+00, -1.1846e+00,  ..., -1.0670e+00,\n           -2.3442e+00,  3.8118e-01],\n          [ 1.3204e-01, -6.3489e-01,  2.0899e-01,  ..., -1.3858e+00,\n           -1.2845e+00,  1.6646e+00],\n          [-3.2653e-01, -2.1050e-01,  1.2989e+00,  ..., -1.6718e+00,\n           -3.6593e-01,  3.5035e-01],\n          ...,\n          [-8.8188e-01, -8.3001e-01,  1.4896e+00,  ...,  7.7194e-02,\n            1.5539e-01, -4.1449e-01],\n          [ 8.4520e-01,  7.3507e-01,  7.6848e-01,  ..., -1.6244e-01,\n            8.1657e-01, -1.7686e+00],\n          [-2.6558e-01, -1.1976e-02, -1.5041e+00,  ...,  4.3979e-01,\n           -9.9115e-01, -2.4289e+00]],\n\n         [[-1.2052e+00, -2.2649e+00,  8.8863e-01,  ..., -7.0927e-01,\n            2.3974e-02, -3.7202e-01],\n          [ 4.3680e-02,  7.3321e-01, -7.5660e-01,  ...,  1.1440e+00,\n            1.7511e-01,  8.8495e-01],\n          [ 1.0251e-01,  9.1809e-01,  1.3595e-01,  ..., -4.8051e-01,\n            7.8040e-01,  6.9223e-01],\n          ...,\n          [ 7.8219e-01,  1.2183e+00, -7.2925e-01,  ..., -1.7236e+00,\n            8.5059e-01,  2.4347e-01],\n          [-1.7311e+00, -6.7418e-01, -2.0939e+00,  ..., -5.9692e-01,\n           -8.2672e-01,  1.1301e+00],\n          [-3.1848e+00, -1.3800e+00, -1.2370e+00,  ..., -4.6079e-01,\n            4.3117e-01,  3.2379e-01]],\n\n         ...,\n\n         [[-1.7981e+00,  9.4158e-01, -1.9356e+00,  ..., -4.1918e-02,\n           -8.6727e-01, -7.9418e-02],\n          [-5.3732e-01,  1.9604e+00,  4.8339e-01,  ...,  1.9706e+00,\n            8.2183e-01, -3.0612e-01],\n          [-7.1462e-02, -3.3465e-01, -4.4499e-01,  ...,  3.4357e-01,\n           -8.0887e-01,  2.6672e+00],\n          ...,\n          [-1.4091e+00, -7.0528e-01, -5.2427e-01,  ..., -3.6863e-02,\n            2.3084e-03, -2.0339e-01],\n          [ 9.9653e-01, -7.0328e-01,  2.4551e-01,  ...,  3.5538e-01,\n           -6.0271e-01,  9.5000e-02],\n          [ 6.4646e-01, -6.9135e-01,  1.0540e+00,  ..., -8.7756e-02,\n           -5.0504e-01, -5.2256e-02]],\n\n         [[-3.3921e-01,  1.6418e-01, -9.5662e-01,  ..., -1.0726e+00,\n            5.6879e-01,  1.1565e+00],\n          [-1.2901e+00, -1.3024e+00, -3.4265e-01,  ...,  4.8478e-01,\n           -4.9420e-01,  8.6845e-01],\n          [-1.7293e+00, -1.9253e-01, -1.2178e+00,  ...,  3.9316e-01,\n           -1.1085e+00,  3.2191e-01],\n          ...,\n          [ 2.7718e-01, -7.6167e-01,  8.6454e-01,  ...,  2.2299e-01,\n           -8.1721e-01, -5.1853e-02],\n          [ 1.9823e-01,  1.6797e-02, -4.3899e-01,  ...,  7.8354e-02,\n            1.5383e+00, -2.2676e-01],\n          [ 3.6751e-01, -9.8327e-01, -1.6724e+00,  ..., -2.0395e-01,\n           -1.2576e+00,  3.1559e-01]],\n\n         [[ 1.0097e+00,  1.4580e+00,  1.6103e+00,  ...,  1.0925e+00,\n           -1.3541e+00,  9.0132e-01],\n          [ 7.1053e-01, -7.5129e-01,  3.4644e-01,  ...,  2.3892e-01,\n            1.1811e+00, -1.0903e+00],\n          [ 1.5378e+00,  1.2657e-02, -6.3386e-01,  ..., -1.6466e-01,\n           -1.7674e+00,  9.5574e-01],\n          ...,\n          [ 1.6799e+00,  1.5439e+00,  4.1174e-01,  ...,  8.3936e-01,\n            8.4483e-01, -1.6113e-01],\n          [ 1.1078e+00, -1.7101e-01, -3.5099e-01,  ...,  1.5877e+00,\n           -1.2924e+00,  1.0140e+00],\n          [-4.5855e-01, -1.4199e-01,  8.4404e-01,  ...,  2.1821e-01,\n           -1.6603e-01,  1.5669e-01]]]])"
     },
     "metadata": {},
     "execution_count": 76
    }
   ],
   "source": [
    "scores = torch.randn(64, 8, 20, 20)\n",
    "mask = torch.ones(64, 20)\n",
    "mask = mask.unsqueeze(1).unsqueeze(1)\n",
    "scores.masked_fill(mask==0, -1e9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}